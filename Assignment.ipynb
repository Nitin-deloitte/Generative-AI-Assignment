{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46a88f1",
   "metadata": {},
   "source": [
    "# Summarization and Chat with Pdf Using Langchain\n",
    "\n",
    "### Objective:\n",
    "The aim of this assignment is to develop a Generative AI application using Large Language\n",
    "Models (LLM) that can take multiple page document of any formats as inputs, learn and\n",
    "summarize their content, and accurately answer user questions related to the documents.\n",
    "The application should be conversational and maintain proper session management. This\n",
    "use case is ideal for individuals and businesses seeking to streamline their document\n",
    "management process, improve productivity, and save time and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252effe5",
   "metadata": {},
   "source": [
    "## Add OpenApi Key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46a5e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a506d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nitin2/Documents/GenerativeAIAssignment'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8786980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import tiktoken\n",
    "import hashlib\n",
    "import textwrap\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '/home/nitin2/Downloads/YouTubeMarketingGuide.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d00acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from IPython.display import display, Javascript\n",
    "def load_document(FILE_PATH): \n",
    "    print(\"Loading Pdf....\")\n",
    "    loader = PyPDFLoader(FILE_PATH)\n",
    "    #print(loader.metadata)\n",
    "    docs=loader.load_and_split()\n",
    "    #generate_newhash(docs)\n",
    "    #print(new_hash)\n",
    "    #new_doc = clean_doc(docs)\n",
    "    print(\"Document is ready...\")\n",
    "    return docs\n",
    "    \n",
    "#cleaning text\n",
    "def clean_doc(docs):\n",
    "    # Convert the list of documents into a string\n",
    "    doc_string = ' '.join([doc.page_content for doc in docs])\n",
    "    # Replace '\\n' characters with a space\n",
    "    doc_string = doc_string.replace('\\n', '')\n",
    "    print(doc_string) \n",
    "    return doc_string\n",
    "\n",
    "def generate_newhash(docs):\n",
    "    pdf_name = FILE_PATH.split('/')[-1]\n",
    "    new_hash = hashlib.md5(''.join([t.page_content for t in docs]).encode()).hexdigest()\n",
    "    print(\"new hash\",new_hash)\n",
    "    current_dir = os.getcwd()\n",
    "    new_dir = current_dir + '/'+pdf_name+'/hash.txt'\n",
    "    print(new_dir)\n",
    "    # Path \n",
    "    path = os.path.join(current_dir, pdf_name)\n",
    "    os.mkdir(path) \n",
    "    with open(new_dir, \"w+\") as file:\n",
    "        file.write(new_hash)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ade25",
   "metadata": {},
   "source": [
    "## Loading Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "\n",
    "#def restart_kernel():\n",
    " #   display(Javascript('IPython.notebook.kernel.restart();'))\n",
    "\n",
    "# Call the function to restart the kernel\n",
    "#restart_kernel()\n",
    "FILE_PATH = input(\"Enter File Path..\")\n",
    "docs = load_document(FILE_PATH)\n",
    "#docs = loader.load_and_split()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd706c",
   "metadata": {},
   "source": [
    "## Summarizing with map_reduce\n",
    "This method involves an initial prompt on each chunk of data * ( for summarization tasks, this could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk). Then a different prompt is run to combine all the initial outputs. This is implemented in the LangChain as the MapReduceDocumentsChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b75cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This article provides a 10-step guide to creating a successful YouTube marketing strategy. It covers topics such as creating a YouTube channel, researching competition, optimizing videos, scheduling videos, optimizing the channel, YouTube advertising, influencer marketing, and analyzing and adapting. It also provides tips on keyword research, creating a video description, optimizing for the YouTube algorithm, and using tools such as Mentionlytics and Hootsuite to track progress.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\")\n",
    "summary = chain.run(docs)   \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracking each step with verbose true\n",
    "chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"map_reduce\",\n",
    "                             verbose=True\n",
    "                             )\n",
    "output_summary = chain.run(docs)\n",
    "\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0623a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for summarizing each part\n",
    "# Default Prompt template using first\n",
    "chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcdf8955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for combining the parts\n",
    "chain.combine_document_chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcbf85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary with Custom Prompts\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "{text}\n",
    "\n",
    "CONSCISE SUMMARY IN BULLET POINTS:\"\"\"\n",
    "\n",
    "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28036ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• YouTube is the most popular website in the world after Google, with over 2 billion users and 72% of American internet users regularly browsing the platform. \n",
      "• To market your business on YouTube, you need to create content that your target customers want, optimize your content for the YouTube algorithm, and set up a YouTube channel with a Google account.\n",
      "• Research your audience and competition, use social listening, and create a SWOT analysis.\n",
      "• Optimize your videos to get more views, create a compelling title, write a description, add tags, create custom thumbnails, and use end screens and cards.\n",
      "• Try YouTube advertising and influencer marketing, and track your progress with analytics.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm,      \n",
    "                             chain_type=\"map_reduce\",\n",
    "                             map_prompt=BULLET_POINT_PROMPT, \n",
    "                             combine_prompt=BULLET_POINT_PROMPT)\n",
    "\n",
    "# chain.llm_chain.prompt= BULLET_POINT_PROMPT\n",
    "# chain.combine_document_chain.llm_chain.prompt= BULLET_POINT_PROMPT\n",
    "output_summary = chain.run(docs)\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a574c",
   "metadata": {},
   "source": [
    "### Now let's start with chat with pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004a382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced6dc1",
   "metadata": {},
   "source": [
    "#### Text Splitter\n",
    "This takes the text and splits it into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa04fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the documents into chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a0d961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892036d",
   "metadata": {},
   "source": [
    "### Making a Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65526a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e8c30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the index from the disk\n"
     ]
    }
   ],
   "source": [
    "pdf_name = FILE_PATH.split('/')[-1]\n",
    "new_hash = hashlib.md5(''.join([t.page_content for t in docs]).encode()).hexdigest()\n",
    "if os.path.exists(\"faiss_index\"+pdf_name):\n",
    "    if os.path.exists(os.path.join(\"faiss_index\"+pdf_name,'hash.txt')):\n",
    "        with open(os.path.join(\"faiss_index\"+pdf_name,'hash.txt'),'r') as f:\n",
    "            stored_hash = f.read().strip()\n",
    "        if new_hash == stored_hash:\n",
    "            print(\"loading the index from the disk\")\n",
    "            db = FAISS.load_local(\"faiss_index\"+pdf_name,embeddings)\n",
    "        else:\n",
    "            print(\"Creating new Index..\")\n",
    "            db = FAISS.from_documents(docs, embeddings)\n",
    "            db.save_local(\"faiss_index\"+pdf_name) \n",
    "            print(\"Index Created\")\n",
    "else:\n",
    "    print(\"Creating new Index..\")\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    db.save_local(\"faiss_index\"+pdf_name)\n",
    "    print(\"Index Created\")\n",
    "    with open(os.path.join(\"faiss_index\"+pdf_name,'hash.txt'),'w') as f:\n",
    "        f.write(new_hash)\n",
    "    print(\"Successfully Created Hash file\")\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a37723d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method OpenAIEmbeddings.embed_query of OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4afecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what are Dietary Supplements\"\n",
    "embedding_vector = embeddings.embed_query(query)\n",
    "docs_and_scores = db.similarity_search_by_vector(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5fce0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "\n",
    "# create a chain to answer questions \n",
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aafe699b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' YouTube marketing is the practice of promoting a brand, product, or service on YouTube. It can involve a mix of tactics, including (but not limited to): creating organic promotional videos, working with influencers, and advertising on the platform.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is youtube marketing\"\n",
    "result = qa({\"question\": query})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca77d1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' YouTube marketing is the practice of promoting a brand, product, or service on YouTube. It can involve a mix of tactics, including (but not limited to): creating organic promotional videos, working with influencers, and advertising on the platform.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what was the previous question?\"\n",
    "result = qa({\"question\": query})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1defb70d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_memory=ChatMessageHistory(messages=[HumanMessage(content='what is youtube marketing', additional_kwargs={}, example=False), AIMessage(content=' YouTube marketing is the practice of promoting a brand, product, or service on YouTube. It can involve a mix of tactics, including (but not limited to): creating organic promotional videos, working with influencers, and advertising on the platform.', additional_kwargs={}, example=False), HumanMessage(content='what was the previous question?', additional_kwargs={}, example=False), AIMessage(content=' YouTube marketing is the practice of promoting a brand, product, or service on YouTube. It can involve a mix of tactics, including (but not limited to): creating organic promotional videos, working with influencers, and advertising on the platform.', additional_kwargs={}, example=False)]) output_key=None input_key=None return_messages=True human_prefix='Human' ai_prefix='AI' memory_key='chat_history'\n"
     ]
    }
   ],
   "source": [
    "print(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b7990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
